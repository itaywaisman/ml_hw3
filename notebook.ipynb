{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-64409fe0",
   "display_name": "PyCharm (ml_hw2)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing.preprocess import split\n",
    "from utils.save_to_csv import save_data_to_csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/virus_hw2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3500, 38)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_to_csv(X_train, X_val, X_test, y_train, y_val, y_test, suffix='before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.preprocess import DataPreprocessor \n",
    "from preprocessing.transformations import fix_label_type \n",
    "\n",
    "preprocess = DataPreprocessor()\n",
    "\n",
    "X_train = preprocess.fit_transform(X_train, y_train)\n",
    "X_val = preprocess.transform(X_val)\n",
    "X_test = preprocess.transform(X_test)\n",
    "\n",
    "y_train = fix_label_type(y_train)\n",
    "y_val = fix_label_type(y_val)\n",
    "y_test = fix_label_type(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(preprocess, open('dumps/preprocessor.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_to_csv(X_train, X_val, X_test, y_train, y_val, y_test, suffix='after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(labels=['PatientID'], axis=1)\n",
    "X_val = X_val.drop(labels=['PatientID'], axis=1)\n",
    "X_test = X_test.drop(labels=['PatientID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, X, y, param_grid):\r\n",
    "    clf = GridSearchCV(estimator=model, param_grid=param_grid,\r\n",
    "                    n_jobs=-1)\r\n",
    "    clf.fit(X, y)\r\n",
    "    return clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Training ###\n",
      "# Fitting for column Virus\n",
      "## Fitting model SVC\n",
      "## Fitting model KNN\n",
      "## Fitting model RandomForest\n",
      "## Fitting model LogisticRegression\n",
      "## Fitting model PolynomialLogisticRegression\n",
      "# Fitting for column Spreader\n",
      "## Fitting model SVC\n",
      "## Fitting model KNN\n",
      "## Fitting model RandomForest\n",
      "## Fitting model LogisticRegression\n",
      "## Fitting model PolynomialLogisticRegression\n",
      "# Fitting for column AtRisk\n",
      "## Fitting model SVC\n",
      "## Fitting model KNN\n",
      "## Fitting model RandomForest\n",
      "## Fitting model LogisticRegression\n",
      "## Fitting model PolynomialLogisticRegression\n"
     ]
    }
   ],
   "source": [
    "print('### Training ###')\n",
    "models = [('SVC', svm.SVC(), dict(C= np.logspace(-10, 10, 10), kernel=['rbf','poly'])),\n",
    "          ('KNN', KNeighborsClassifier(), dict(n_neighbors=np.linspace(2,10,9, dtype=int))),\n",
    "          ('RandomForest', RandomForestClassifier(max_depth=10, random_state=0), dict(max_depth=np.linspace(2,16,15))),\n",
    "          ('LogisticRegression', LogisticRegression(random_state=0), dict()),\n",
    "          ('PolynomialLogisticRegression',  Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                  ('linear', LogisticRegression())]), dict())]\n",
    "\n",
    "models_per_column = dict()\n",
    "\n",
    "for column in y_train.columns:\n",
    "    print(f'# Fitting for column {column}')\n",
    "    fitted_models = []\n",
    "    for name, model, param_grid in models:\n",
    "        print(f'## Fitting model {name}')\n",
    "        clf = grid_search(model, X_train, y_train[column], param_grid)\n",
    "        fitted_models.append((name, clf))\n",
    "    models_per_column[column] = fitted_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Validation Scores ###\n",
      "#########################################\n",
      "# checking for column Virus\n",
      "# scoring for model SVC\n",
      "accuracy: 0.6093333333333333\n",
      "percision: 0.6042516610641108\n",
      "recall score: 0.6606950636870573\n",
      "f1 score: 0.6473322181177784\n",
      "# scoring for model KNN\n",
      "accuracy: 0.448\n",
      "percision: 0.4542934562379429\n",
      "recall score: 0.34400915242085794\n",
      "f1 score: 0.3643691927446406\n",
      "# scoring for model RandomForest\n",
      "accuracy: 0.816\n",
      "percision: 0.8225967629546949\n",
      "recall score: 0.7981104032830184\n",
      "f1 score: 0.8226055202738474\n",
      "# scoring for model LogisticRegression\n",
      "accuracy: 0.5786666666666667\n",
      "percision: 0.5741198941255136\n",
      "recall score: 0.5821970991056432\n",
      "f1 score: 0.5676599049394694\n",
      "# scoring for model PolynomialLogisticRegression\n",
      "accuracy: 0.644\n",
      "percision: 0.6422904822091414\n",
      "recall score: 0.6778170674437738\n",
      "f1 score: 0.6803151291414454\n",
      "#########################################\n",
      "# checking for column Spreader\n",
      "# scoring for model SVC\n",
      "accuracy: 0.8226666666666667\n",
      "percision: 0.8179487179487179\n",
      "recall score: 0.8372703412073491 (PREFERED)\n",
      "f1 score: 0.827496757457847\n",
      "# scoring for model KNN\n",
      "accuracy: 0.728\n",
      "percision: 0.6886993603411514\n",
      "recall score: 0.847769028871391 (PREFERED)\n",
      "f1 score: 0.7600000000000001\n",
      "# scoring for model RandomForest\n",
      "accuracy: 0.872\n",
      "percision: 0.8553615960099751\n",
      "recall score: 0.9002624671916011 (PREFERED)\n",
      "f1 score: 0.8772378516624042\n",
      "# scoring for model LogisticRegression\n",
      "accuracy: 0.848\n",
      "percision: 0.8396946564885496\n",
      "recall score: 0.8661417322834646 (PREFERED)\n",
      "f1 score: 0.8527131782945735\n",
      "# scoring for model PolynomialLogisticRegression\n",
      "accuracy: 0.8373333333333334\n",
      "percision: 0.834625322997416\n",
      "recall score: 0.847769028871391 (PREFERED)\n",
      "f1 score: 0.8411458333333334\n",
      "#########################################\n",
      "# checking for column AtRisk\n",
      "# scoring for model SVC\n",
      "accuracy: 0.7573333333333333\n",
      "percision: 0.7526041666666666\n",
      "recall score: 0.7686170212765957 (PREFERED)\n",
      "f1 score: 0.7605263157894736\n",
      "# scoring for model KNN\n",
      "accuracy: 0.5666666666666667\n",
      "percision: 0.5836065573770491\n",
      "recall score: 0.4734042553191489 (PREFERED)\n",
      "f1 score: 0.5227606461086637\n",
      "# scoring for model RandomForest\n",
      "accuracy: 0.7666666666666667\n",
      "percision: 0.7583547557840618\n",
      "recall score: 0.7845744680851063 (PREFERED)\n",
      "f1 score: 0.7712418300653595\n",
      "# scoring for model LogisticRegression\n",
      "accuracy: 0.7573333333333333\n",
      "percision: 0.770949720670391\n",
      "recall score: 0.7340425531914894 (PREFERED)\n",
      "f1 score: 0.7520435967302451\n",
      "# scoring for model PolynomialLogisticRegression\n",
      "accuracy: 0.736\n",
      "percision: 0.7431693989071039\n",
      "recall score: 0.723404255319149 (PREFERED)\n",
      "f1 score: 0.7331536388140162\n"
     ]
    }
   ],
   "source": [
    "print('### Validation Scores ###')\n",
    "\n",
    "print('#########################################')\n",
    "print(f'# checking for column Virus')\n",
    "column = 'Virus'\n",
    "fitted_models = models_per_column[column]\n",
    "for name, model in fitted_models:\n",
    "    print(f'# scoring for model {name}')\n",
    "    y_hat = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val[column], y_hat)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    percision = precision_score(y_val[column],y_hat, average='weighted')\n",
    "    print(f'percision: {percision}')\n",
    "    recall = recall_score(y_val[column],y_hat, average='macro')\n",
    "    print(f'recall score: {recall}')\n",
    "    f1 = f1_score(y_val[column],y_hat, average='macro')\n",
    "    print(f'f1 score: {f1}')\n",
    "\n",
    "print('#########################################')\n",
    "print(f'# checking for column Spreader')\n",
    "column = 'Spreader'\n",
    "fitted_models = models_per_column[column]\n",
    "for name, model in fitted_models:\n",
    "    print(f'# scoring for model {name}')\n",
    "    y_hat = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val[column], y_hat)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    percision = precision_score(y_val[column],y_hat, average=\"binary\", pos_label=\"Spreader\")\n",
    "    print(f'percision: {percision}')\n",
    "    recall = recall_score(y_val[column],y_hat, average=\"binary\", pos_label=\"Spreader\")\n",
    "    print(f'recall score: {recall} (PREFERED)')\n",
    "    f1 = f1_score(y_val[column],y_hat, average=\"binary\", pos_label=\"Spreader\")\n",
    "    print(f'f1 score: {f1}')\n",
    "\n",
    "\n",
    "print('#########################################')\n",
    "print(f'# checking for column AtRisk')\n",
    "column = 'AtRisk'\n",
    "fitted_models = models_per_column[column]\n",
    "for name, model in fitted_models:\n",
    "    print(f'# scoring for model {name}')\n",
    "    y_hat = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val[column], y_hat)\n",
    "    print(f'accuracy: {accuracy}')\n",
    "    percision = precision_score(y_val[column],y_hat , average=\"binary\", pos_label=\"atRisk\")\n",
    "    print(f'percision: {percision}')\n",
    "    recall = recall_score(y_val[column],y_hat, average=\"binary\", pos_label=\"atRisk\")\n",
    "    print(f'recall score: {recall} (PREFERED)')\n",
    "    f1 = f1_score(y_val[column],y_hat, average=\"binary\", pos_label=\"atRisk\")\n",
    "    print(f'f1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_score_map = {'Virus' : (precision_score, {'average':'weighted'}), \n",
    "    'Spreader': (recall_score, {'average': \"binary\", 'pos_label': \"Spreader\"}), \n",
    "    'AtRisk': (recall_score, {'average': \"binary\", 'pos_label': \"atRisk\"})}\n",
    "\n",
    "best_models = dict()\n",
    "\n",
    "for column in ['Virus', 'Spreader', 'AtRisk']:\n",
    "    fitted_models = models_per_column[column]\n",
    "    best_model, best_score = None, -1\n",
    "    for name, model in fitted_models:\n",
    "        y_hat = model.predict(X_val)\n",
    "        score_function, params =  column_score_map[column]\n",
    "        score = score_function(y_val[column], y_hat, **params)\n",
    "        if score > best_score:\n",
    "            best_model, best_score = model, score\n",
    "    \n",
    "    best_models[column] = (best_model, best_score)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-da6cc4fb5c64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dumps/best_models.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "pickle.dump(best_models, open('dumps/best_models.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Testing Scores ###\n#########################################\n# checking for column Virus\naccuracy: 0.8146666666666667\npercision: 0.8191983854193686\nrecall score: 0.7811885765110382\nf1 score: 0.811035758513396\n#########################################\n# checking for column Spreader\naccuracy: 0.8666666666666667\npercision: 0.8356164383561644\nrecall score: 0.8840579710144928 (PREFERED)\nf1 score: 0.8591549295774648\n#########################################\n# checking for column AtRisk\naccuracy: 0.76\npercision: 0.7288557213930348\nrecall score: 0.804945054945055 (PREFERED)\nf1 score: 0.7650130548302873\n"
     ]
    }
   ],
   "source": [
    "print('### Testing Scores ###')\n",
    "\n",
    "print('#########################################')\n",
    "print(f'# checking for column Virus')\n",
    "column = 'Virus'\n",
    "model, _  = best_models['Virus']\n",
    "y_hat = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test[column], y_hat)\n",
    "print(f'accuracy: {accuracy}')\n",
    "percision = precision_score(y_test[column],y_hat, average='weighted')\n",
    "print(f'percision: {percision}')\n",
    "recall = recall_score(y_test[column],y_hat, average='macro')\n",
    "print(f'recall score: {recall}')\n",
    "f1 = f1_score(y_test[column],y_hat, average='macro')\n",
    "print(f'f1 score: {f1}')\n",
    "\n",
    "print('#########################################')\n",
    "print(f'# checking for column Spreader')\n",
    "column = 'Spreader'\n",
    "model,_ = best_models['Spreader']\n",
    "y_hat = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test[column], y_hat)\n",
    "print(f'accuracy: {accuracy}')\n",
    "percision = precision_score(y_test[column],y_hat, average=\"binary\", pos_label=\"Spreader\")\n",
    "print(f'percision: {percision}')\n",
    "recall = recall_score(y_test[column],y_hat, average=\"binary\", pos_label=\"Spreader\")\n",
    "print(f'recall score: {recall} (PREFERED)')\n",
    "f1 = f1_score(y_test[column],y_hat, average=\"binary\", pos_label=\"Spreader\")\n",
    "print(f'f1 score: {f1}')\n",
    "\n",
    "\n",
    "print('#########################################')\n",
    "print(f'# checking for column AtRisk')\n",
    "column = 'AtRisk'\n",
    "model, _ = best_models['AtRisk']\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test[column], y_hat)\n",
    "print(f'accuracy: {accuracy}')\n",
    "percision = precision_score(y_test[column],y_hat , average=\"binary\", pos_label=\"atRisk\")\n",
    "print(f'percision: {percision}')\n",
    "recall = recall_score(y_test[column],y_hat, average=\"binary\", pos_label=\"atRisk\")\n",
    "print(f'recall score: {recall} (PREFERED)')\n",
    "f1 = f1_score(y_test[column],y_hat, average=\"binary\", pos_label=\"atRisk\")\n",
    "print(f'f1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown = pd.read_csv('data/virus_hw3_unlabeled.csv')\n",
    "\n",
    "X_unknown = df_unknown.drop(labels=['TestResultsCode'], axis=1) \n",
    "X_unknown = preprocess.transform(X_unknown)\n",
    "\n",
    "\n",
    "patientIds = X_unknown['PatientID']\n",
    "X_unknown = X_unknown.drop(labels=['PatientID'], axis=1)\n",
    "\n",
    "\n",
    "y_pred = pd.DataFrame()\n",
    "y_pred['Virus'] = pd.Series(best_models['Virus'][0].predict(X_unknown))\n",
    "y_pred['Spreader'] = pd.Series(best_models['Spreader'][0].predict(X_unknown))\n",
    "y_pred['AtRisk'] = pd.Series(best_models['AtRisk'][0].predict(X_unknown))\n",
    "\n",
    "y_pred['TestResultsCode'] = y_pred[['Virus', 'Spreader', 'AtRisk']].agg('_'.join, axis=1)\n",
    "\n",
    "Result =  pd.concat([patientIds, y_pred['TestResultsCode']], axis=1)\n",
    "\n",
    "Result.to_csv('results/predicted.csv', index=False)"
   ]
  }
 ]
}